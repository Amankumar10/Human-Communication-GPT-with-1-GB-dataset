{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abe2435",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_human_gpt_small.py\n",
    "------------------------\n",
    "Train a small GPT-style model on your 12 MB human communication dataset.\n",
    "Works on CPU or GPU.\n",
    "\"\"\"\n",
    "\n",
    "import os, torch, torch.nn as nn, torch.nn.functional as F\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bb69539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.5.1+cu121\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: c:\\users\\aman\\desktop\\human-communication-gpt-with-1-gb-dataset\\env\\lib\\site-packages\n",
      "Requires: fsspec, networkx, jinja2, filelock, typing-extensions, sympy\n",
      "Required-by: torchvision\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "806babe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- Config -----------------------\n",
    "DATA_PATH = \"data/human_chat.txt\"\n",
    "MODEL_PATH = \"checkpoints/human_gpt_small.pt\"\n",
    "\n",
    "BLOCK_SIZE = 256    # shorter context (small data)\n",
    "BATCH_SIZE = 32       # reduce for limited VRAM\n",
    "N_EMBD = 128\n",
    "N_HEAD = 4\n",
    "N_LAYER = 2\n",
    "DROPOUT = 0.1\n",
    "N_EMBD = 96       # smaller embedding\n",
    "LR = 2e-4   \n",
    "STEPS = 20000          # you can raise to 8000 for better quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2af56470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“– Loading dataset...\n",
      "âœ… Loaded 12,950,920 characters from data/human_chat.txt\n",
      "ðŸ§© Using GPT-2 BPE tokenizer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§© Vocab size (BPE): 50257\n",
      "ðŸ“Š Tokens: train=3238109, val=359790\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- Load Dataset -----------------------\n",
    "print(\"ðŸ“– Loading dataset...\")\n",
    "text = open(DATA_PATH, encoding=\"utf-8\").read()\n",
    "print(f\"âœ… Loaded {len(text):,} characters from {DATA_PATH}\")\n",
    "\n",
    "import tiktoken\n",
    "print(\"ðŸ§© Using GPT-2 BPE tokenizer...\")\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "def encode(s): return enc.encode(s)\n",
    "def decode(l): return enc.decode(l)\n",
    "\n",
    "text = open(DATA_PATH, encoding=\"utf-8\").read()\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "vocab_size = enc.n_vocab\n",
    "print(f\"ðŸ§© Vocab size (BPE): {vocab_size}\")\n",
    "\n",
    "n = int(0.9 * len(data))\n",
    "train_data, val_data = data[:n], data[n:]\n",
    "print(f\"ðŸ“Š Tokens: train={len(train_data)}, val={len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da98bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- Model Definition -----------------------\n",
    "class MiniGPT(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd=N_EMBD, n_head=N_HEAD,\n",
    "                 n_layer=N_LAYER, block_size=BLOCK_SIZE, dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embeddings\n",
    "        self.token_emb = nn.Embedding(vocab_size, n_embd)\n",
    "        self.pos_emb = nn.Embedding(block_size, n_embd)\n",
    "\n",
    "        # Transformer blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=n_embd,\n",
    "                nhead=n_head,\n",
    "                dim_feedforward=4 * n_embd,\n",
    "                dropout=dropout,\n",
    "                batch_first=True\n",
    "            )\n",
    "            for _ in range(n_layer)\n",
    "        ])\n",
    "\n",
    "        # Final normalization + dropout + output head\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.dropout = nn.Dropout(0.1)         # âœ… add this line\n",
    "        self.head = nn.Linear(n_embd, vocab_size)\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_emb(idx)\n",
    "        pos_emb = self.pos_emb(torch.arange(T, device=idx.device))\n",
    "        x = tok_emb + pos_emb\n",
    "\n",
    "        # pass through each transformer block\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        # final layer norm + dropout\n",
    "        x = self.ln_f(x)\n",
    "        x = self.dropout(x)                    # âœ… add this line\n",
    "\n",
    "        logits = self.head(x)\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d094fb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Using device: cuda\n",
      "ðŸ§  Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/20000 [00:00<1:06:02,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 00000 | Loss: 11.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 503/20000 [00:52<31:47, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 00500 | Loss: 5.4459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 1003/20000 [01:45<31:07, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 01000 | Loss: 4.6508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 1503/20000 [02:37<30:14, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 01500 | Loss: 4.4977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 2003/20000 [03:29<29:25, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 02000 | Loss: 4.4498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 2503/20000 [04:22<28:39, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 02500 | Loss: 4.3582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 3003/20000 [05:14<27:59, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 03000 | Loss: 4.1279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 3503/20000 [06:07<27:14, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 03500 | Loss: 4.3573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 4003/20000 [07:00<27:13,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 04000 | Loss: 3.9943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–Ž       | 4503/20000 [07:53<25:48, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 04500 | Loss: 3.9672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 5003/20000 [08:45<24:47, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 05000 | Loss: 3.6397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 5503/20000 [09:38<24:14,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 05500 | Loss: 3.1963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 6003/20000 [10:31<23:08, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 06000 | Loss: 2.1225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6503/20000 [11:24<22:07, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 06500 | Loss: 1.7585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7003/20000 [12:16<21:20, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 07000 | Loss: 1.1834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 7503/20000 [13:09<20:42, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 07500 | Loss: 0.9839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8003/20000 [14:02<19:29, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 08000 | Loss: 0.7547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 8503/20000 [14:54<18:56, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 08500 | Loss: 0.5548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9003/20000 [15:47<18:04, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 09000 | Loss: 0.4668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 9503/20000 [16:40<17:13, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 09500 | Loss: 0.4241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10003/20000 [17:33<16:28, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10000 | Loss: 0.2782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10503/20000 [18:26<16:04,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10500 | Loss: 0.2173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11003/20000 [19:19<14:49, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11000 | Loss: 0.2138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11503/20000 [20:12<14:08, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11500 | Loss: 0.1477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12003/20000 [21:05<13:08, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12000 | Loss: 0.1324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12503/20000 [21:58<12:20, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12500 | Loss: 0.1274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13003/20000 [22:50<11:32, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13000 | Loss: 0.0960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13503/20000 [23:42<10:29, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13500 | Loss: 0.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14003/20000 [24:34<09:41, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14000 | Loss: 0.0798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14503/20000 [25:25<08:53, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14500 | Loss: 0.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15003/20000 [26:17<08:05, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15000 | Loss: 0.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 15503/20000 [27:09<07:17, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15500 | Loss: 0.0556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16003/20000 [28:01<06:27, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16000 | Loss: 0.0571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 16503/20000 [28:53<05:44, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16500 | Loss: 0.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17003/20000 [29:46<04:55, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17000 | Loss: 0.0451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 17503/20000 [30:38<04:06, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17500 | Loss: 0.0407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18003/20000 [31:30<03:16, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18000 | Loss: 0.0311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 18503/20000 [32:23<02:27, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18500 | Loss: 0.0282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19003/20000 [33:15<01:38, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19000 | Loss: 0.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 19503/20000 [34:08<00:49, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19500 | Loss: 0.0355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [35:00<00:00,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19999 | Loss: 0.0380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- Training -----------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ðŸš€ Using device: {device}\")\n",
    "model = MiniGPT(vocab_size).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "def get_batch(split):\n",
    "    data_split = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data_split) - BLOCK_SIZE, (BATCH_SIZE,))\n",
    "    x = torch.stack([data_split[i:i+BLOCK_SIZE] for i in ix])\n",
    "    y = torch.stack([data_split[i+1:i+BLOCK_SIZE+1] for i in ix])\n",
    "    return x.to(device), y.to(device)\n",
    "\n",
    "print(\"ðŸ§  Starting training...\")\n",
    "for step in tqdm(range(STEPS)):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    _, loss = model(xb, yb)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if step % 500 == 0 or step == STEPS - 1:\n",
    "        print(f\"Step {step:05d} | Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25356809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# ðŸ’¬ TEXT GENERATION\n",
    "# ==========================\n",
    "def generate(model, start=\"User: Hello!\\nBot:\", max_new_tokens=150, temperature=0.9):\n",
    "    model.eval()\n",
    "    idx = torch.tensor([encode(start)], dtype=torch.long).to(device)\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -model.block_size:]\n",
    "        logits, _ = model(idx_cond)\n",
    "        logits = logits[:, -1, :] / temperature\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat((idx, next_id), dim=1)\n",
    "    return decode(idx[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7310a091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== GENERATED RESPONSE ==================\n",
      "\n",
      "\n",
      "User1: You never reply to my messages.\n",
      "User2: I was busy with work.\n",
      "Please help me communicate better.\n",
      "Bot:\n",
      "\n",
      " never crashed help me. I to catch my car. Somh po. Generally crashed me true\n",
      " SC. Ifh po If slamming sometime\n",
      "I gave po If me  po If po If If po po. If Always help If my plea shown. peaceful!! better spill to my work busy wanted work my preferences me1est. po true! If If embarrassed po trust catch trust tastes never busy! Cheap po rocks If po say po true If If true embarrassed po po repeat If there properties freeze coaching. If proceed po owes me out. po If trust true po If embarrassed callates tastes true po If rent gre true.. If If helping flooded coaching. If true! If proceed rocked shower po po. Senior cardio prank hack true DOES slamming\n",
      "\n",
      "========================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================\n",
    "# ðŸ¤– TEST CHAT GENERATION\n",
    "# ==========================\n",
    "prompt = \"\"\"\n",
    "User1: You never reply to my messages.\n",
    "User2: I was busy with work.\n",
    "Please help me communicate better.\n",
    "Bot:\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n================== GENERATED RESPONSE ==================\\n\")\n",
    "print(generate(model, start=prompt, temperature=0.7, max_new_tokens=150))\n",
    "print(\"\\n========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d237e1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31d948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42557d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c387c011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
